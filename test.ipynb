{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from data.dataset import NERDataset\n",
    "from models.utils import Namespace, getSignal\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence, pad_sequence, PackedSequence\n",
    "from models.networks import GlobalContextualDeepTransition\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceName = 'data/conll03/eng.train.src'\n",
    "targetName = 'data/conll03/eng.train.trg'\n",
    "gloveFile = 'data/conll03/trimmed.300d.Cased.txt'\n",
    "symbFile = 'data/conll03/sym.glove'\n",
    "testSrc = 'data/conll03/eng.testb.src'\n",
    "testTrg = 'data/conll03/eng.testb.trg'\n",
    "\n",
    "data = NERDataset(sourceName, targetName, gloveFile, symbFile)\n",
    "data.readTestFile(testSrc, testTrg)\n",
    "loader = data.getLoader(1024, shuffle=False)\n",
    "# loader = DataLoader(data, collate_fn=data.pack_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevCheckpointPath = 'lightning_logs/checkpoint-v0.ckpt'\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    kwargs = json.load(file)\n",
    "    \n",
    "model = GlobalContextualDeepTransition.load_from_checkpoint(prevCheckpointPath, **kwargs)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logitsToLogProbs(logits):\n",
    "    return logits - torch.logsumexp(logits, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    words, chars, charMask, targets = batch = next(iter(loader))\n",
    "    encoded, initHiddenState, initPrevTarget = model.encode(words, chars, charMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathSum(values, logProbs):\n",
    "    \"\"\"\n",
    "        Adds the prev sum to current logProbs\n",
    "        to get the effective logprob\n",
    "    \"\"\"\n",
    "    # values is batch, beam\n",
    "    values = torch.unsqueeze(values, -1) # batch, beam, 1\n",
    "    values = values.repeat(1, 1, units)  # batch, beam, units\n",
    "    values = values.permute(1,0,2)       # beam, batch, units\n",
    "    values = torch.cat(list(values), -1) # batch, units * beam\n",
    "    \n",
    "    # logprobs is [batch, units*beam]\n",
    "    ps = logProbs + values\n",
    "    \n",
    "    # ps is [batch, units*beam]\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchSize=47, beamSize=4, units=256\n"
     ]
    }
   ],
   "source": [
    "batchSize = words.batch_sizes[0].item() # batchSize\n",
    "beamSize  = 4 # beamsize\n",
    "units = model.sequenceLabeller.decoderUnits\n",
    "print(f\"batchSize={batchSize}, beamSize={beamSize}, units={units}\")\n",
    "\n",
    "lengths = torch.zeros(batchSize, dtype=torch.int)\n",
    "live = list(range(batchSize))\n",
    "dead = []\n",
    "\n",
    "for x in words.batch_sizes:\n",
    "    lengths[:x] += 1\n",
    "\n",
    "\"\"\"\n",
    "    values[i, j] contains the heuristic beam of the ith example. j in range(beamSize)\n",
    "    paths [i, j] contains the corresponding paths\n",
    "\"\"\"\n",
    "values = torch.zeros(batchSize, beamSize) # we maintain a queue like tensor, each example has a queue of size beamSize\n",
    "paths  = [ [list() for _ in range(beamSize)] for _ in range(batchSize) ] # one node in each queue as root of tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Init nodes in a matrix for each beam and \"\"\"\n",
    "\n",
    "# encoded pages\n",
    "start = 0\n",
    "encodedPages = []\n",
    "for pageLen in words.batch_sizes:\n",
    "    if start == 0:\n",
    "        page = encoded[start:start+pageLen] # first page is not repeated\n",
    "    else:\n",
    "        page = encoded[start:start+pageLen].repeat(beamSize, 1)\n",
    "    encodedPages.append(page) # [e1, e2, e3, e1, e2, e3.. etc, repeated beamSize times]\n",
    "    start += pageLen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12, 13, 15, 14],\n",
      "        [12, 13, 15, 14],\n",
      "        [12, 13, 15, 14],\n",
      "        [12, 13, 15, 14],\n",
      "        [12,  7, 14, 13],\n",
      "        [12, 13, 14,  7],\n",
      "        [12, 13, 15, 14],\n",
      "        [12,  7, 14,  3],\n",
      "        [12,  7, 14,  3],\n",
      "        [12, 13, 15, 14],\n",
      "        [12,  7, 14, 13],\n",
      "        [12,  7, 14,  3],\n",
      "        [12,  9,  0,  7],\n",
      "        [12, 13, 15, 14],\n",
      "        [12,  0,  9,  7],\n",
      "        [12,  7, 14,  0],\n",
      "        [12, 13, 15, 14],\n",
      "        [12,  7, 14,  3],\n",
      "        [12, 13, 14, 15],\n",
      "        [12,  7, 14,  0],\n",
      "        [12, 13, 15, 14],\n",
      "        [12, 13, 15, 14],\n",
      "        [12,  9,  0, 14],\n",
      "        [12,  7,  9,  0],\n",
      "        [12, 13, 15, 14],\n",
      "        [12,  7, 14,  3],\n",
      "        [12, 13, 15, 14],\n",
      "        [12,  9,  0, 14],\n",
      "        [12,  7, 14,  3],\n",
      "        [12, 13, 14, 15],\n",
      "        [12,  7,  9,  0],\n",
      "        [12, 13, 15, 16],\n",
      "        [12,  7, 14,  3],\n",
      "        [12, 14,  7,  3],\n",
      "        [12,  0,  9, 14],\n",
      "        [12, 13, 15, 16],\n",
      "        [12,  9,  0,  7],\n",
      "        [12, 13, 14, 15],\n",
      "        [12,  9,  0,  7],\n",
      "        [12, 13, 15, 14],\n",
      "        [12, 13, 14, 15],\n",
      "        [12, 13, 15, 14],\n",
      "        [12, 13, 15, 14],\n",
      "        [12, 13, 14, 15],\n",
      "        [12, 13, 15, 14],\n",
      "        [12, 13, 14, 15],\n",
      "        [12,  7,  5,  9]])\n",
      "torch.Size([188, 256])\n",
      "torch.Size([47, 256])\n"
     ]
    }
   ],
   "source": [
    "# initial values are not repeated\n",
    "hiddenState = initHiddenState\n",
    "prevTarget = initPrevTarget\n",
    "\n",
    "\n",
    "for t, b in enumerate(words.batch_sizes):\n",
    "    \"\"\"Get the previous target and make the forward pass\"\"\"\n",
    "    if t == 0:\n",
    "        actualSize = b.item()\n",
    "    else:\n",
    "        actualSize = b.item() * beamSize\n",
    "    prevTarget = prevTarget[:actualSize] + getSignal(1, units, t, model.device)\n",
    "    with torch.no_grad():\n",
    "        hiddenState, logits = model.sequenceLabeller.decode_once(\n",
    "            encodedPages[t],\n",
    "            prevTarget,\n",
    "            hiddenState\n",
    "        )\n",
    "    logProbs = logitsToLogProbs(logits) # [b*beamSize, units] ie [l1, l2, l3, l1, l2, l3 ... numTag d vectors repeated]\n",
    "\n",
    "    \"\"\"Add the logProbs to the current paths to get newPathSums\"\"\"\n",
    "    if t == 0:\n",
    "        ps = logProbs\n",
    "    else:\n",
    "        logProbs = logProbs.reshape((beamSize, b.item(), units)) # now becomes [[l1, l2, l3], [l1, l2, l3], [l1, l2, l3]...]\n",
    "        logProbs = torch.cat(list(logProbs), dim=-1) # [l1l1l1..., l2l2l2..., l3l3l3...]\n",
    "        ps = pathSum(values, logProbs)\n",
    "\n",
    "    \"\"\"Filter the top beam pathsums and extend the paths\"\"\"\n",
    "    values, indices = ps.topk(dim=-1, k=beamSize) # values is [batch, beam]\n",
    "\n",
    "    # indices represent max over arrays of size units * beam\n",
    "    # Their parent must be at idx/units in the queue.\n",
    "    parents = indices // units\n",
    "\n",
    "    # the child is the actual index\n",
    "    children = indices % units\n",
    "\n",
    "    \"\"\"Extend paths using new values\"\"\"\n",
    "    numFinished = 0\n",
    "    for qidx, valBeam, childbeam, parentBeam in zip(live, values, children, parents):\n",
    "        \"\"\"\n",
    "            Narrow our sight to each example:\n",
    "                At qidx, extend the path of parentBeam[i] with childBeam[i]\n",
    "                You will get beam no. of new paths.\n",
    "                This is your new path beam.\n",
    "        \"\"\"\n",
    "        newQueue = []\n",
    "        for v, c, p in zip(valBeam, childbeam, parentBeam):\n",
    "            oldPath = paths[qidx][p]\n",
    "            newPath = oldPath + [c.item()]\n",
    "            newQueue.append(newPath)\n",
    "        paths[qidx] = newQueue\n",
    "\n",
    "        \"\"\"Mark completed if the lenghts of the paths match the word count\"\"\"\n",
    "        if len(newQueue[0]) == lengths[qidx]:\n",
    "            numFinished += 1\n",
    "            dead.append(qidx)\n",
    "\n",
    "    \"\"\"If an example is done, it has to be at the end of the live array\"\"\"\n",
    "    for _ in range(numFinished):\n",
    "        live.pop()\n",
    "\n",
    "    \"\"\"\n",
    "        Rearrange the prevTarget and hiddenState using indices\n",
    "        Note that values = torch.gather(ps, -1, indices) is a way to go from [batch, units*beam] and [batch, beam]\n",
    "\n",
    "        * ps -> [batch, units*beam] and values -> [batch, beam]\n",
    "    \"\"\"\n",
    "    print(indices) \n",
    "    prevTarget = model.sequenceLabeller.targetEmbedding(indices.reshape(-1))\n",
    "#     hiddenState = torch.gather(hiddenState, -1, indices)\n",
    "    print(prevTarget.shape)\n",
    "    print(hiddenState.shape)\n",
    "    break\n",
    "# print(*[page.shape for page in encodedPages], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([\n",
    "    [1,2,3],\n",
    "    [4, 5, 6]\n",
    "]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 5\n",
    "beamSize = 4\n",
    "\n",
    "hs = torch.randn(batchSize, 256)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
