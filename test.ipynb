{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from data.dataset import NERDataset\n",
    "from models.utils import Namespace\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence, pad_sequence, PackedSequence\n",
    "from models.networks import GlobalContextualDeepTransition\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceName = 'data/conll03/eng.train.src'\n",
    "targetName = 'data/conll03/eng.train.trg'\n",
    "gloveFile = 'data/conll03/trimmed.300d.Cased.txt'\n",
    "symbFile = 'data/conll03/sym.glove'\n",
    "testSrc = 'data/conll03/eng.testb.src'\n",
    "testTrg = 'data/conll03/eng.testb.trg'\n",
    "\n",
    "data = NERDataset(sourceName, targetName, gloveFile, symbFile)\n",
    "data.readTestFile(testSrc, testTrg)\n",
    "loader = data.getLoader(1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevCheckpointPath = 'lightning_logs/checkpoint-v0.ckpt'\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    kwargs = json.load(file)\n",
    "    \n",
    "model = GlobalContextualDeepTransition.load_from_checkpoint(prevCheckpointPath, **kwargs)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logitsToLogProbs(logits):\n",
    "    return logits - torch.logsumexp(logits, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "At any point, we store\n",
    "    index\n",
    "    timeTillNow\n",
    "    pathFollowedTillNow\n",
    "    hValue\n",
    "for the sole purpose of backtracking\n",
    "\n",
    "We declare a matrix(batch_size, beam_size) of these to store info\n",
    "\"\"\"\n",
    "class Node:\n",
    "    def __init__(self, path=[], value=0):\n",
    "#         self.index  = index\n",
    "#         self.time   = time\n",
    "        self.path   = path\n",
    "        self.value =  value\n",
    "#         self.hiddenState = hiddenState\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "    def expandable(self, targetLen):\n",
    "        return len(self.path) < targetLen\n",
    "    \n",
    "    def expandWithChoices(self, choices, logProbs):\n",
    "        newNodes = []\n",
    "        for choice, logProb in zip(choices, logProbs):\n",
    "            newNodes.append( Node(self.path+[choice], self.value+logProb) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    words, chars, charMask, targets = batch\n",
    "    encoded, initHiddenState, initPrevTarget = model.encode(words, chars, charMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchSize=47, beamSize=4, units=256\n"
     ]
    }
   ],
   "source": [
    "batchSize = words.batch_sizes[0].item() # batchSize\n",
    "beamSize  = 4 # beamsize\n",
    "units = model.sequenceLabeller.decoderUnits\n",
    "print(f\"batchSize={batchSize}, beamSize={beamSize}, units={units}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Init nodes in a matrix for each beam and \"\"\"\n",
    "\n",
    "# encoded pages\n",
    "start = 0\n",
    "encodedPages = []\n",
    "for pageLen in words.batch_sizes:\n",
    "    page = encoded[start:start+pageLen].repeat(beamSize, 1)\n",
    "    encodedPages.append(page) # [e1, e2, e3, e1, e2, e3.. etc, repeated beamSize times]\n",
    "    start += pageLen\n",
    "\n",
    "\n",
    "\n",
    "# state = Namespace(\n",
    "#     nodes = [[Node() for _ in range(beamSize)] for _ in range(batchSize)] # only beamSize choices to backtrack\n",
    "#     encodedPages = encodedPages\n",
    "#     hiddenState = [torch.zeros(page.shape) for page in ]\n",
    "# )\n",
    "\n",
    "# print(*[page.shape for page in encodedPages], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "Repeated\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "Reshaped\n",
      "tensor([[[ 0.1000,  1.1000,  1.9000,  2.9000],\n",
      "         [ 3.9000,  5.1000,  5.9000,  6.9000],\n",
      "         [ 7.9000,  8.9000,  9.9000, 10.9000]],\n",
      "\n",
      "        [[ 0.0000,  1.0000,  2.0000,  3.0000],\n",
      "         [ 4.0000,  5.0000,  6.0000,  7.0000],\n",
      "         [ 8.0000,  9.0000, 10.0000, 11.0000]]])\n",
      "Maximum\n",
      "tensor([[ 0.1000,  1.1000,  2.0000,  3.0000],\n",
      "        [ 4.0000,  5.1000,  6.0000,  7.0000],\n",
      "        [ 8.0000,  9.0000, 10.0000, 11.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial\")\n",
    "x = torch.arange(12, dtype=torch.float).reshape((3, 4))\n",
    "print(x)\n",
    "\n",
    "print(\"Repeated\")\n",
    "x = x.repeat(2, 1)\n",
    "print(x)\n",
    "\n",
    "print(\"Reshaped\")\n",
    "x = x.reshape(2,3,4)\n",
    "x[0] += 0.2 * torch.randint(2, size=(3, 4)) - 0.1\n",
    "print(x)\n",
    "\n",
    "print(\"Maximum\")\n",
    "print(x.max(axis=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnnPlusWarmupDecay(learningRate=8e-3, minValue=5e-6):\n",
    "    def subroutine(step):\n",
    "        \"\"\"\n",
    "            if the resultant lr ( = decay * learning_rate) is very small,\n",
    "            then return decay such that resultant lr becomes minvalue\n",
    "            \n",
    "            that is decay * learning_rate >= minvalue\n",
    "            so decay can never be less than minValue/learning_rate\n",
    "            therefore we max it with the least val\n",
    "            decay = max(decay, minValue/learning_rate)\n",
    "        \"\"\"\n",
    "        exp = (1000 - step) / 3000\n",
    "        decay = min(1, 2 ** exp)\n",
    "        return max(decay, minValue/learningRate)\n",
    "    return subroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.nn.Parameter(torch.randn(3, 4))\n",
    "w2 = torch.nn.Parameter(torch.randn(3, 4))\n",
    "\n",
    "optim = torch.optim.Adam([w1, w2], lr=0.1)\n",
    "sched = torch.optim.lr_scheduler.LambdaLR(optim, rnnPlusWarmupDecay())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.015749013123685915\n",
      "500 0.01403077560386716\n",
      "1000 0.0125\n",
      "1500 0.011136233976754242\n",
      "2000 0.009921256574801246\n",
      "2500 0.008838834764831846\n",
      "3000 0.007874506561842957\n",
      "3500 0.00701538780193358\n",
      "4000 0.00625\n",
      "4500 0.00556811698837712\n",
      "5000 0.004960628287400625\n",
      "5500 0.004419417382415923\n",
      "6000 0.003937253280921478\n",
      "6500 0.0035076939009667917\n",
      "7000 0.003125\n",
      "7500 0.00278405849418856\n",
      "8000 0.0024803141437003125\n",
      "8500 0.0022097086912079614\n"
     ]
    }
   ],
   "source": [
    "for i in range(9000):\n",
    "    loss = w1*w2\n",
    "    loss.sum().backward()\n",
    "    if i%500 == 0:\n",
    "        lr = optim.param_groups[0]['lr']\n",
    "        print(i, lr)\n",
    "    \n",
    "    optim.step()\n",
    "    sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': [Parameter containing:\n",
       "  tensor([[-1.4074, -2.0451, -1.9878, -0.7623],\n",
       "          [-1.5438, -0.5121,  0.6965, -0.7930],\n",
       "          [ 0.0273,  0.6387,  0.3439,  0.0112]], requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([[-1.3529,  0.6924,  0.5541,  0.8220],\n",
       "          [ 0.5065, -1.0960, -0.2883, -0.5091],\n",
       "          [ 1.3843,  1.2723, -0.3518, -1.1477]], requires_grad=True)],\n",
       " 'lr': 9.090909090909092e-05,\n",
       " 'betas': (0.9, 0.999),\n",
       " 'eps': 1e-08,\n",
       " 'weight_decay': 0,\n",
       " 'amsgrad': False,\n",
       " 'initial_lr': 0.001}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.param_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
