{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import NERDataset\n",
    "from models.networks import GlobalContextualDeepTransition\n",
    "import pytorch_lightning as pl\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceName = 'data/conll03/eng.train.src'\n",
    "targetName = 'data/conll03/eng.train.trg'\n",
    "gloveFile = 'data/conll03/trimmed.300d.Cased.txt'\n",
    "symbFile = 'data/conll03/sym.glove'\n",
    "data = NERDataset(sourceName, targetName, gloveFile, symbFile)\n",
    "loader = data.getLoader(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "numChars = 100\n",
    "charEmbedding = 128\n",
    "numWords = len(data.wordIdx)\n",
    "wordEmbedding = 300\n",
    "contextOutputUnits = 128\n",
    "contextTransitionNumber = transitionNumber = 4\n",
    "encoderUnits = 256\n",
    "decoderUnits = 256\n",
    "prevCheckpointPath = 'lightning_logs/version_0/checkpoints/epoch=100.ckpt'\n",
    "kwargs = dict(numChars=numChars, charEmbedding=charEmbedding, numWords=numWords,\n",
    "                 wordEmbedding=wordEmbedding, contextOutputUnits=contextOutputUnits, contextTransitionNumber=contextTransitionNumber,\n",
    "                    encoderUnits=encoderUnits, decoderUnits=decoderUnits, transitionNumber=transitionNumber, numTags=data.numTags)\n",
    "model = GlobalContextualDeepTransition.load_from_checkpoint(prevCheckpointPath, **kwargs)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S-PER', 'O', 'S-PER', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "inp = 'Harvey and Mike have authored this project'\n",
    "\n",
    "inp = re.sub(r'[^\\w\\s]', '', inp)\n",
    "inp = data.encodeSentence(inp)\n",
    "out = model.testForward(inp)\n",
    "out, lens = pad_packed_sequence(out)\n",
    "out = out.view(-1).numpy()\n",
    "\n",
    "print([data.tags[i] for i in out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-LOC B-MISC B-ORG B-PER E-LOC E-MISC E-ORG E-PER I-LOC I-MISC I-ORG I-PER O S-LOC S-MISC S-ORG S-PER\n"
     ]
    }
   ],
   "source": [
    "allTags = ' '.join(data.tags)\n",
    "print(allTags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
