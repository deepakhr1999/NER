{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from data.dataset import NERDataset\n",
    "from models.utils import Namespace, getSignal\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence, pad_sequence, PackedSequence\n",
    "from models.networks import GlobalContextualDeepTransition\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceName = 'data/conll03/eng.train.src'\n",
    "targetName = 'data/conll03/eng.train.trg'\n",
    "gloveFile = 'data/conll03/trimmed.300d.Cased.txt'\n",
    "symbFile = 'data/conll03/sym.glove'\n",
    "testSrc = 'data/conll03/eng.testb.src'\n",
    "testTrg = 'data/conll03/eng.testb.trg'\n",
    "\n",
    "data = NERDataset(sourceName, targetName, gloveFile, symbFile)\n",
    "data.readTestFile(testSrc, testTrg)\n",
    "loader = data.getLoader(1024, shuffle=False)\n",
    "# loader = DataLoader(data, collate_fn=data.pack_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevCheckpointPath = 'lightning_logs/ckpt-epoch=109-train_loss=0.63.ckpt'\n",
    "\n",
    "with open('config.json', 'r') as file:\n",
    "    kwargs = json.load(file)\n",
    "    \n",
    "model = GlobalContextualDeepTransition.load_from_checkpoint(prevCheckpointPath, **kwargs)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logitsToLogProbs(logits):\n",
    "    return logits - torch.logsumexp(logits, dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathSum(values, logProbs):\n",
    "    \"\"\"\n",
    "        Adds the prev sum to current logProbs\n",
    "        to get the effective logprob\n",
    "    \"\"\"\n",
    "    # values is batch, beam\n",
    "    values = torch.unsqueeze(values, -1) # batch, beam, 1\n",
    "    values = values.repeat(1, 1, tags)  # batch, beam, units\n",
    "    values = values.permute(1,0,2)       # beam, batch, units\n",
    "    values = torch.cat(list(values), -1) # batch, units * beam\n",
    "    \n",
    "    # logprobs is [batch, units*beam]\n",
    "    ps = logProbs + values\n",
    "    \n",
    "    # ps is [batch, units*beam]\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamSearch(batch):\n",
    "    with torch.no_grad():\n",
    "        words, chars, charMask, targets = batch\n",
    "        encoded, initHiddenState, initPrevTarget = model.encode(words, chars, charMask)\n",
    "\n",
    "    batchSize = words.batch_sizes[0].item() # batchSize\n",
    "    beamSize  = 4 # beamsize\n",
    "    units = model.sequenceLabeller.decoderUnits\n",
    "    tags = model.numTags\n",
    "\n",
    "#     print(f\"batchSize={batchSize}, beamSize={beamSize}, units={units}, tags={tags}\")\n",
    "\n",
    "    lengths = torch.zeros(batchSize, dtype=torch.int)\n",
    "\n",
    "    for x in words.batch_sizes:\n",
    "        lengths[:x] += 1\n",
    "\n",
    "    \"\"\"\n",
    "        values[i, j] contains the heuristic beam of the ith example. j in range(beamSize)\n",
    "        paths [i, j] contains the corresponding paths\n",
    "    \"\"\"\n",
    "    values = torch.zeros(batchSize, beamSize) # we maintain a queue like tensor, each example has a queue of size beamSize\n",
    "    paths  = [ [list() for _ in range(beamSize)] for _ in range(batchSize) ] # one node in each queue as root of tree\n",
    "    \"\"\"Init nodes in a matrix for each beam and \"\"\"\n",
    "\n",
    "    # encoded pages\n",
    "    start = 0\n",
    "    encodedPages = []\n",
    "    for pageLen in words.batch_sizes:\n",
    "        if start == 0:\n",
    "            page = encoded[start:start+pageLen] # first page is not repeated\n",
    "        else:\n",
    "            page = encoded[start:start+pageLen].repeat(beamSize, 1)\n",
    "        encodedPages.append(page) # [e1, e2, e3, e1, e2, e3.. etc, repeated beamSize times]\n",
    "        start += pageLen\n",
    "\n",
    "    live = list(range(batchSize))\n",
    "    dead = []\n",
    "\n",
    "    # initial values are not repeated\n",
    "    hiddenState = initHiddenState\n",
    "    prevTarget = initPrevTarget\n",
    "\n",
    "\n",
    "    for t, b in enumerate(words.batch_sizes):\n",
    "        \"\"\"Get the previous target and make the forward pass\"\"\"\n",
    "        if len(live) != b.item():\n",
    "            print(\"kekw\")\n",
    "\n",
    "        prevTarget += getSignal(1, units, t, model.device)\n",
    "        with torch.no_grad():\n",
    "            hiddenState, logits = model.sequenceLabeller.decode_once(\n",
    "                encodedPages[t],\n",
    "                prevTarget,\n",
    "                hiddenState\n",
    "            )\n",
    "        logProbs = logitsToLogProbs(logits) # [b*beamSize, units] ie [l1, l2, l3, l1, l2, l3 ... numTag d vectors repeated]\n",
    "\n",
    "        \"\"\"Add the logProbs to the current paths to get newPathSums\"\"\"\n",
    "        if t == 0:\n",
    "            ps = logProbs\n",
    "        else:\n",
    "            logProbs = logProbs.reshape((-1, b, tags)) # now becomes [[l1, l2, l3], [l1, l2, l3], [l1, l2, l3]...]\n",
    "            logProbs = torch.cat(list(logProbs), dim=-1) # [l1l1l1..., l2l2l2..., l3l3l3...]\n",
    "            ps = pathSum(values[:b], logProbs)\n",
    "\n",
    "        \"\"\"Filter the top beam pathsums and extend the paths\"\"\"\n",
    "        values[:b], indices = ps.topk(dim=-1, k=beamSize) # values is [batch, beam]\n",
    "\n",
    "        parents = indices // tags\n",
    "        children = indices % tags\n",
    "\n",
    "        \"\"\"Extend paths using new values\"\"\"\n",
    "        numFinished = 0\n",
    "        for qidx, valBeam, childbeam, parentBeam in zip(live, values, children, parents):\n",
    "            \"\"\"\n",
    "                Narrow our sight to each example:\n",
    "                    At qidx, extend the path of parentBeam[i] with childBeam[i]\n",
    "                    You will get beam no. of new paths.\n",
    "                    This is your new path beam.\n",
    "            \"\"\"\n",
    "            newQueue = []\n",
    "            for v, c, p in zip(valBeam, childbeam, parentBeam):\n",
    "                oldPath = paths[qidx][p]\n",
    "                newPath = oldPath + [c.item()]\n",
    "                newQueue.append(newPath)\n",
    "            paths[qidx] = newQueue\n",
    "\n",
    "            \"\"\"Mark completed if the lenghts of the paths match the word count\"\"\"\n",
    "            if len(newQueue[0]) == lengths[qidx]:\n",
    "                numFinished += 1\n",
    "                dead.append(qidx)\n",
    "\n",
    "        # remove dead sequences\n",
    "        live = live[:b-numFinished]\n",
    "        children = children[:b-numFinished]\n",
    "        parents = parents[:b-numFinished]\n",
    "        prevTarget = model.sequenceLabeller.targetEmbedding(children.T.reshape(-1))\n",
    "        hiddenState = hiddenState.reshape((-1, b, units))\n",
    "        unfolded = parents.T.reshape(-1)\n",
    "        runner = torch.arange(b-numFinished).repeat(beamSize)\n",
    "        hiddenState = hiddenState[unfolded, runner]\n",
    "        \n",
    "    # decode results\n",
    "    results = [x[0] for x in paths]\n",
    "    unsorted = [results[i] for i in words.unsorted_indices]\n",
    "    return unsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6e6f9a078142fca7b5000901e7d171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for batch in tqdm(loader):\n",
    "    preds.extend(beamSearch(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predsnotebook.pkl', 'wb') as file:\n",
    "    pickle.dump(preds, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'S-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'E-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "['O', 'O', 'S-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'E-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "idx = 7\n",
    "actual = [data.tags[j] for j in data[idx][2]] \n",
    "predicted = unsorted[idx]\n",
    "\n",
    "print(actual)\n",
    "print(predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
