{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import NERDataset\n",
    "from models.networks import GlobalContextualDeepTransition\n",
    "import pytorch_lightning as pl\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceName = 'data/conll03/eng.train.src'\n",
    "targetName = 'data/conll03/eng.train.trg'\n",
    "gloveFile = 'data/conll03/trimmed.300d.Cased.txt'\n",
    "symbFile = 'data/conll03/sym.glove'\n",
    "data = NERDataset(sourceName, targetName, gloveFile, symbFile)\n",
    "loader = data.getLoader(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(21387, 21388)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "max(data.wordIdx.values()), len(data.wordIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numChars = 100\n",
    "charEmbedding = 128\n",
    "numWords = len(data.wordIdx)\n",
    "wordEmbedding = 300\n",
    "contextOutputUnits = 128\n",
    "contextTransitionNumber = transitionNumber = 4\n",
    "encoderUnits = 256\n",
    "decoderUnits = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trainable parameters: 7,313,341\n"
     ]
    }
   ],
   "source": [
    "model = GlobalContextualDeepTransition(numChars, charEmbedding, numWords,\n",
    "                     wordEmbedding, contextOutputUnits, contextTransitionNumber,\n",
    "                        encoderUnits, decoderUnits, transitionNumber, data.numTags)\n",
    "\n",
    "# add glove weights here\n",
    "model.init_weights(data.embeddingWeights)\n",
    "\n",
    "numParams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {numParams:,}\") # 6,788,797 but now 7,313,341 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                           | Params\n",
      "--------------------------------------------------------------------\n",
      "0 | contextEncoder   | GlobalContextualEncoder        | 7 M   \n",
      "1 | sequenceLabeller | SequenceLabelingEncoderDecoder | 6 M   \n",
      "Epoch 0: 100%|██████████| 50/50 [04:27<00:00,  5.35s/it, loss=1.010, v_num=15]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "trainer = pl.Trainer(gradient_clip_val=5., gpus=1, max_epochs=1)\n",
    "trainer.fit(model, loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}